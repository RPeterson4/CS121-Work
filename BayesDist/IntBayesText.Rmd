&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Recall that in the frequentist philosophy we only have a data distribution, X, with no prior distribution. Yet, in order to distinguish significant findings, the frequentist philosophy often employs hypothesis tests with p-values judged according to arbitrary cut-offs (most commonly p = .05). Moreover, the hypothesis test and p-value cut-off might be thought of as a conditional probability, and can be generally phrased in the following: given this hypothesis, what’s the probability that we observe this data or something more extreme?


&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The Bayesian approach, however, flips this frame of thought on its head. Consider that the prior distribution captures our prior beliefs about a parameter, often a probability. The data distribution then updates the prior to form the posterior distribution. Here, the posterior allows us to derive a new hypothesis test, in which we claim some interval of the posterior distribution supports or contradicts the hypothesis. For example, if we’re testing to see whether we have a weighted coin (a binary variable) with the Beta Binomial model, we might hypothesize that for $p$, the interval (.25, 75) of the Beta posterior indicates a “fair” coin whereas the intervals from [0, .25] and [.75, 1] indicate a “weighted” coin. Moreover, we can calculate the probabilities of $p$ falling in such intervals by integrating the area under the curve. But consider this process in comparison to the frequentist philosophy. We just took the data to derive a posterior that then leads to a probability indicating whether a parameter falls within a hypothesized interval. Phrased like before, we have: given this data, what’s the probability that this hypothesis is correct? And with that, we have also eliminated p-values from our analysis.
